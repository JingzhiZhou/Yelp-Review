{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## for processing\n",
    "import re\n",
    "import nltk\n",
    "## for bag-of-words\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing,feature_selection\n",
    "## for explainer\n",
    "from lime import lime_text\n",
    "## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "## for bert language model\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>useful_level</th>\n",
       "      <th>language</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>read_ease</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Adj_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073206</td>\n",
       "      <td>JdReKgETiiJEDmshrO4TLw</td>\n",
       "      <td>pyarmAnR-i-qookQamqRTA</td>\n",
       "      <td>V2GOReqPvr8qpCC7sWfoTw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Just to let this car company that people DO re...</td>\n",
       "      <td>2014-03-06 12:38:52</td>\n",
       "      <td>moderate useful</td>\n",
       "      <td>en</td>\n",
       "      <td>let car company people read yelp check review ...</td>\n",
       "      <td>85.49</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6229216</td>\n",
       "      <td>zL4se_Ixdcl8kvTOHCS3rg</td>\n",
       "      <td>s16-BUo-orUsELvMu5ocKg</td>\n",
       "      <td>VH0Ib9S3E-dxbQdQC4rffg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Mistral was the worst dining experience I have...</td>\n",
       "      <td>2010-07-22 18:08:01</td>\n",
       "      <td>moderate useful</td>\n",
       "      <td>en</td>\n",
       "      <td>mistral worst dining experience ever life bad ...</td>\n",
       "      <td>79.19</td>\n",
       "      <td>0.029864</td>\n",
       "      <td>0.502499</td>\n",
       "      <td>0.225888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7607157</td>\n",
       "      <td>wlLQ42QMHiQMJISCTUVX5A</td>\n",
       "      <td>aQA2eIdEC3_ZDHwUregu8A</td>\n",
       "      <td>wygOtij7aEb7dTdTFFnOcw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Took a VIP tour with DeMon of the Atlanta Merc...</td>\n",
       "      <td>2020-02-04 16:05:20</td>\n",
       "      <td>not useful</td>\n",
       "      <td>en</td>\n",
       "      <td>took vip tour demon atlanta mercedes benz stad...</td>\n",
       "      <td>-32.40</td>\n",
       "      <td>0.422500</td>\n",
       "      <td>0.696111</td>\n",
       "      <td>0.218750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id                 user_id  \\\n",
       "0     1073206  JdReKgETiiJEDmshrO4TLw  pyarmAnR-i-qookQamqRTA   \n",
       "1     6229216  zL4se_Ixdcl8kvTOHCS3rg  s16-BUo-orUsELvMu5ocKg   \n",
       "2     7607157  wlLQ42QMHiQMJISCTUVX5A  aQA2eIdEC3_ZDHwUregu8A   \n",
       "\n",
       "              business_id  stars  useful  funny  cool  \\\n",
       "0  V2GOReqPvr8qpCC7sWfoTw    1.0      17      1     0   \n",
       "1  VH0Ib9S3E-dxbQdQC4rffg    1.0      15      6     4   \n",
       "2  wygOtij7aEb7dTdTFFnOcw    5.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Just to let this car company that people DO re...  2014-03-06 12:38:52   \n",
       "1  Mistral was the worst dining experience I have...  2010-07-22 18:08:01   \n",
       "2  Took a VIP tour with DeMon of the Atlanta Merc...  2020-02-04 16:05:20   \n",
       "\n",
       "      useful_level language  \\\n",
       "0  moderate useful       en   \n",
       "1  moderate useful       en   \n",
       "2       not useful       en   \n",
       "\n",
       "                                          text_clean  read_ease  polarity  \\\n",
       "0  let car company people read yelp check review ...      85.49 -0.500000   \n",
       "1  mistral worst dining experience ever life bad ...      79.19  0.029864   \n",
       "2  took vip tour demon atlanta mercedes benz stad...     -32.40  0.422500   \n",
       "\n",
       "   subjectivity  Adj_ratio  \n",
       "0      1.000000   0.120000  \n",
       "1      0.502499   0.225888  \n",
       "2      0.696111   0.218750  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=pd.read_csv('Review_project_sentiment.csv')\n",
    "review.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>useful_level</th>\n",
       "      <th>language</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>read_ease</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Adj_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073206</td>\n",
       "      <td>JdReKgETiiJEDmshrO4TLw</td>\n",
       "      <td>pyarmAnR-i-qookQamqRTA</td>\n",
       "      <td>V2GOReqPvr8qpCC7sWfoTw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Just to let this car company that people DO re...</td>\n",
       "      <td>2014-03-06 12:38:52</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>let car company people read yelp check review ...</td>\n",
       "      <td>85.49</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6229216</td>\n",
       "      <td>zL4se_Ixdcl8kvTOHCS3rg</td>\n",
       "      <td>s16-BUo-orUsELvMu5ocKg</td>\n",
       "      <td>VH0Ib9S3E-dxbQdQC4rffg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Mistral was the worst dining experience I have...</td>\n",
       "      <td>2010-07-22 18:08:01</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>mistral worst dining experience ever life bad ...</td>\n",
       "      <td>79.19</td>\n",
       "      <td>0.029864</td>\n",
       "      <td>0.502499</td>\n",
       "      <td>0.225888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7607157</td>\n",
       "      <td>wlLQ42QMHiQMJISCTUVX5A</td>\n",
       "      <td>aQA2eIdEC3_ZDHwUregu8A</td>\n",
       "      <td>wygOtij7aEb7dTdTFFnOcw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Took a VIP tour with DeMon of the Atlanta Merc...</td>\n",
       "      <td>2020-02-04 16:05:20</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>took vip tour demon atlanta mercedes benz stad...</td>\n",
       "      <td>-32.40</td>\n",
       "      <td>0.422500</td>\n",
       "      <td>0.696111</td>\n",
       "      <td>0.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141509</td>\n",
       "      <td>OMw52-Eo-BYFHdUldLMc5Q</td>\n",
       "      <td>mmr-P0i__uQJHGXXeVjXxg</td>\n",
       "      <td>0Ng-wDNyA-96uaJZP8EKZg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>When I first came here for the first time last...</td>\n",
       "      <td>2015-03-09 22:42:06</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>first came first time last year best friend ap...</td>\n",
       "      <td>83.96</td>\n",
       "      <td>0.168452</td>\n",
       "      <td>0.419841</td>\n",
       "      <td>0.168831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7962637</td>\n",
       "      <td>RWq78T9FIyauVHaHj7yl9g</td>\n",
       "      <td>CyCI71vLDa923zOMeDDA5w</td>\n",
       "      <td>WUfZXjTtBUbezJE7LnWABw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I only got the take-out, so I cannot speak of ...</td>\n",
       "      <td>2013-03-22 20:47:40</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>got takeout cannot speak service food good wou...</td>\n",
       "      <td>51.86</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id                 user_id  \\\n",
       "0     1073206  JdReKgETiiJEDmshrO4TLw  pyarmAnR-i-qookQamqRTA   \n",
       "1     6229216  zL4se_Ixdcl8kvTOHCS3rg  s16-BUo-orUsELvMu5ocKg   \n",
       "2     7607157  wlLQ42QMHiQMJISCTUVX5A  aQA2eIdEC3_ZDHwUregu8A   \n",
       "3      141509  OMw52-Eo-BYFHdUldLMc5Q  mmr-P0i__uQJHGXXeVjXxg   \n",
       "4     7962637  RWq78T9FIyauVHaHj7yl9g  CyCI71vLDa923zOMeDDA5w   \n",
       "\n",
       "              business_id  stars  useful  funny  cool  \\\n",
       "0  V2GOReqPvr8qpCC7sWfoTw    1.0      17      1     0   \n",
       "1  VH0Ib9S3E-dxbQdQC4rffg    1.0      15      6     4   \n",
       "2  wygOtij7aEb7dTdTFFnOcw    5.0       0      0     0   \n",
       "3  0Ng-wDNyA-96uaJZP8EKZg    4.0      40      0     0   \n",
       "4  WUfZXjTtBUbezJE7LnWABw    3.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Just to let this car company that people DO re...  2014-03-06 12:38:52   \n",
       "1  Mistral was the worst dining experience I have...  2010-07-22 18:08:01   \n",
       "2  Took a VIP tour with DeMon of the Atlanta Merc...  2020-02-04 16:05:20   \n",
       "3  When I first came here for the first time last...  2015-03-09 22:42:06   \n",
       "4  I only got the take-out, so I cannot speak of ...  2013-03-22 20:47:40   \n",
       "\n",
       "  useful_level language                                         text_clean  \\\n",
       "0            1       en  let car company people read yelp check review ...   \n",
       "1            1       en  mistral worst dining experience ever life bad ...   \n",
       "2            0       en  took vip tour demon atlanta mercedes benz stad...   \n",
       "3            2       en  first came first time last year best friend ap...   \n",
       "4            0       en  got takeout cannot speak service food good wou...   \n",
       "\n",
       "   read_ease  polarity  subjectivity  Adj_ratio  \n",
       "0      85.49 -0.500000      1.000000   0.120000  \n",
       "1      79.19  0.029864      0.502499   0.225888  \n",
       "2     -32.40  0.422500      0.696111   0.218750  \n",
       "3      83.96  0.168452      0.419841   0.168831  \n",
       "4      51.86  0.320000      0.780000   0.200000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder\n",
    "review1=review\n",
    "review1.loc[review1['useful_level']==\"useful\",'useful_level']=2\n",
    "review1.loc[review1['useful_level']==\"moderate useful\",'useful_level']=1\n",
    "review1.loc[review1['useful_level']==\"not useful\",'useful_level']=0\n",
    "\n",
    "#encoder1=LabelEncoder()\n",
    "#review1['useful_level'] = encoder1.fit_transform(review1['useful_level'].values)\n",
    "review1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1.to_csv('review_sentiment_encoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从这里开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1=pd.read_csv(r'C:\\Users\\11638\\Favorites\\Code\\Project\\fan\\Data\\review_sentiment_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tf-Idf (advanced variant of BoW)\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(max_features=5000, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split dataset\n",
    "dtf_train, dtf_test = model_selection.train_test_split(review1, test_size=0.3)\n",
    "## get target\n",
    "y_train = dtf_train[\"useful_level\"].values\n",
    "y_test = np.array(dtf_test[\"useful_level\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = dtf_train[\"text_clean\"]\n",
    "vectorizer.fit(corpus1)\n",
    "X_train = vectorizer.transform(corpus1)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38630, 5000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dtf_train[\"useful_level\"]\n",
    "X_names = vectorizer.get_feature_names()\n",
    "p_value_limit = 0.95\n",
    "dtf_features = pd.DataFrame()\n",
    "for cat in np.unique(y):\n",
    "    chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "    dtf_features = dtf_features.append(pd.DataFrame(\n",
    "                   {\"feature\":X_names, \"score\":1-p, \"y\":cat}))\n",
    "    dtf_features = dtf_features.sort_values([\"y\",\"score\"], \n",
    "                    ascending=[True,False])\n",
    "    dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "X_names = dtf_features[\"feature\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0:\n",
      "  . selected features: 1545\n",
      "  . top features: amazing,company,food,great,atmosphere,call,told,doctor,pizza,review\n",
      " \n",
      "# 1:\n",
      "  . selected features: 557\n",
      "  . top features: great,car,food,apartment,call,said,office,told,doctor,amazing\n",
      " \n",
      "# 2:\n",
      "  . selected features: 431\n",
      "  . top features: ride,park,food,ron,great,disney,tattoo,store,grandson,lash\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for cat in np.unique(y):\n",
    "    print(\"# {}:\".format(cat))\n",
    "    print(\"  . selected features:\",\n",
    "         len(dtf_features[dtf_features[\"y\"]==cat]))\n",
    "    print(\"  . top features:\", \",\".join(\n",
    "dtf_features[dtf_features[\"y\"]==cat][\"feature\"].values[:10]))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit vecorizor\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
    "vectorizer.fit(corpus1)\n",
    "X_train = vectorizer.transform(corpus1)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = dtf_test[\"text_clean\"]\n",
    "X_test= vectorizer.transform(corpus2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 停"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifier)])\n",
    "## train classifier\n",
    "model[\"classifier\"].fit(X_train, y_train.astype(int))\n",
    "## test\n",
    "X_test = dtf_test[\"text_clean\"].values\n",
    "predicted = model.predict(X_test)\n",
    "#predicted = np.argmax(predicted,axis=1)\n",
    "predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4933844182710021 0.5495284065115231 0.5079293973412745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "f1 = f1_score( y_test, predicted, average='macro' )\n",
    "p = precision_score(y_test, predicted, average='macro')\n",
    "r = recall_score(y_test, predicted, average='macro')\n",
    "\n",
    "print(f1, p, r)\n",
    "# output: 0.555555555556 0.5 0.666666666667\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "Auc: 0.73\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71      7327\n",
      "           1       0.49      0.54      0.51      5222\n",
      "           2       0.53      0.17      0.26      4008\n",
      "\n",
      "    accuracy                           0.57     16557\n",
      "   macro avg       0.55      0.51      0.49     16557\n",
      "weighted avg       0.56      0.57      0.54     16557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, \n",
    "                            multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重新开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllotherTrain = dtf_train[[\"useful_level\", \"read_ease\", \"polarity\", \"subjectivity\", \"Adj_ratio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbeddingTrain = pd.DataFrame(X_train.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['useful_level','read_ease','polarity','subjectivity','Adj_ratio']:\n",
    "    EmbeddingTrain[i] = AllotherTrain[i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>company</th>\n",
       "      <th>food</th>\n",
       "      <th>great</th>\n",
       "      <th>atmosphere</th>\n",
       "      <th>call</th>\n",
       "      <th>told</th>\n",
       "      <th>doctor</th>\n",
       "      <th>pizza</th>\n",
       "      <th>review</th>\n",
       "      <th>...</th>\n",
       "      <th>nicely</th>\n",
       "      <th>popped</th>\n",
       "      <th>overpriced</th>\n",
       "      <th>tourist</th>\n",
       "      <th>caribbean</th>\n",
       "      <th>useful_level</th>\n",
       "      <th>read_ease</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Adj_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.71</td>\n",
       "      <td>0.382955</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.14</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030002</td>\n",
       "      <td>0.034298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-42.14</td>\n",
       "      <td>0.099065</td>\n",
       "      <td>0.468141</td>\n",
       "      <td>0.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.92</td>\n",
       "      <td>0.163417</td>\n",
       "      <td>0.503500</td>\n",
       "      <td>0.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.319599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-25.29</td>\n",
       "      <td>0.092721</td>\n",
       "      <td>0.489664</td>\n",
       "      <td>0.147887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38625</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.53</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38626</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38627</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>67.18</td>\n",
       "      <td>0.157917</td>\n",
       "      <td>0.442302</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38628</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.18</td>\n",
       "      <td>0.194643</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38629</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32.77</td>\n",
       "      <td>0.062816</td>\n",
       "      <td>0.404061</td>\n",
       "      <td>0.136111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38630 rows × 1640 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        amazing   company      food     great  atmosphere  call      told  \\\n",
       "0      0.000000  0.000000  0.000000  0.000000         0.0   0.0  0.000000   \n",
       "1      0.000000  0.000000  0.000000  0.000000         0.0   0.0  0.000000   \n",
       "2      0.030002  0.034298  0.000000  0.000000         0.0   0.0  0.027971   \n",
       "3      0.000000  0.103333  0.000000  0.000000         0.0   0.0  0.000000   \n",
       "4      0.000000  0.121432  0.000000  0.000000         0.0   0.0  0.066021   \n",
       "...         ...       ...       ...       ...         ...   ...       ...   \n",
       "38625  0.000000  0.000000  0.000000  0.211778         0.0   0.0  0.000000   \n",
       "38626  0.000000  0.000000  0.000000  0.000000         0.0   0.0  0.000000   \n",
       "38627  0.000000  0.000000  0.073666  0.000000         0.0   0.0  0.000000   \n",
       "38628  0.000000  0.000000  0.000000  0.000000         0.0   0.0  0.000000   \n",
       "38629  0.000000  0.000000  0.000000  0.000000         0.0   0.0  0.000000   \n",
       "\n",
       "       doctor  pizza    review  ...  nicely  popped  overpriced  tourist  \\\n",
       "0         0.0    0.0  0.000000  ...     0.0     0.0         0.0      0.0   \n",
       "1         0.0    0.0  0.000000  ...     0.0     0.0         0.0      0.0   \n",
       "2         0.0    0.0  0.027081  ...     0.0     0.0         0.0      0.0   \n",
       "3         0.0    0.0  0.000000  ...     0.0     0.0         0.0      0.0   \n",
       "4         0.0    0.0  0.319599  ...     0.0     0.0         0.0      0.0   \n",
       "...       ...    ...       ...  ...     ...     ...         ...      ...   \n",
       "38625     0.0    0.0  0.000000  ...     0.0     0.0         0.0      0.0   \n",
       "38626     0.0    0.0  0.000000  ...     0.0     0.0         0.0      0.0   \n",
       "38627     0.0    0.0  0.000000  ...     0.0     0.0         0.0      0.0   \n",
       "38628     0.0    0.0  0.000000  ...     0.0     0.0         0.0      0.0   \n",
       "38629     0.0    0.0  0.000000  ...     0.0     0.0         0.0      0.0   \n",
       "\n",
       "       caribbean  useful_level  read_ease  polarity  subjectivity  Adj_ratio  \n",
       "0            0.0             0      75.71  0.382955      0.484848   0.133333  \n",
       "1            0.0             0      82.14 -0.266667      0.400000   0.111111  \n",
       "2            0.0             2     -42.14  0.099065      0.468141   0.179487  \n",
       "3            0.0             1      42.92  0.163417      0.503500   0.101695  \n",
       "4            0.0             2     -25.29  0.092721      0.489664   0.147887  \n",
       "...          ...           ...        ...       ...           ...        ...  \n",
       "38625        0.0             0      52.53  0.355000      0.565000   0.352941  \n",
       "38626        0.0             1      72.02  0.050000      0.775000   0.133333  \n",
       "38627        0.0             2      67.18  0.157917      0.442302   0.277778  \n",
       "38628        0.0             0      85.18  0.194643      0.552381   0.225000  \n",
       "38629        0.0             2      32.77  0.062816      0.404061   0.136111  \n",
       "\n",
       "[38630 rows x 1640 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmbeddingTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewXTrain = EmbeddingTrain.loc[:, EmbeddingTrain.columns != 'useful_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewYTrain = EmbeddingTrain.loc[:, EmbeddingTrain.columns == 'useful_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewYTrain = EmbeddingTrain.loc[:, EmbeddingTrain.columns == 'useful_level'].values\n",
    "#NewYTrain = np.ravel(NewYTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllotherTest = dtf_test[[\"useful_level\", \"read_ease\", \"polarity\", \"subjectivity\", \"Adj_ratio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbeddingTest = pd.DataFrame(X_test.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['useful_level','read_ease','polarity','subjectivity','Adj_ratio']:\n",
    "    EmbeddingTest[i] = AllotherTest[i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewXTest = EmbeddingTest.loc[:, EmbeddingTest.columns != 'useful_level']\n",
    "NewYTest = EmbeddingTest.loc[:, EmbeddingTest.columns == 'useful_level'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewYTest = EmbeddingTest.loc[:, EmbeddingTest.columns == 'useful_level'].values\n",
    "#NewYTest = np.ravel(NewYTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11638\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.67\n",
      "Accuracy of Logistic regression classifier on test set: 0.62\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter = 5000)\n",
    "logreg.fit(NewXTrain, NewYTrain)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(NewXTrain, NewYTrain)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(NewXTest, NewYTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(NewXTrain, NewYTrain)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(NewXTrain, NewYTrain)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(NewXTest, NewYTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11638\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA classifier on training set: 0.67\n",
      "Accuracy of LDA classifier on test set: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(NewXTrain, NewYTrain)\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
    "     .format(lda.score(NewXTrain, NewYTrain)))\n",
    "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
    "     .format(lda.score(NewXTest, NewYTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(NewXTrain, NewYTrain)\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
    "     .format(gnb.score(NewXTrain, NewYTrain)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
    "     .format(gnb.score(NewXTest, NewYTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(NewXTrain, NewYTrain)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(NewXTrain, NewYTrain)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(NewXTest, NewYTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
