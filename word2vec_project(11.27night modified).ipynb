{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## for processing\n",
    "import re\n",
    "import nltk\n",
    "## for bag-of-words\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing,feature_selection\n",
    "## for explainer\n",
    "from lime import lime_text\n",
    "## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "## for bert language model\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review=pd.read_csv(r'C:\\Users\\11638\\Favorites\\Code\\Project\\Review_project_sentiment_wUser.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>read_ease</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Adj_ratio</th>\n",
       "      <th>review_count</th>\n",
       "      <th>NumElite</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>NumofWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073206</td>\n",
       "      <td>JdReKgETiiJEDmshrO4TLw</td>\n",
       "      <td>pyarmAnR-i-qookQamqRTA</td>\n",
       "      <td>V2GOReqPvr8qpCC7sWfoTw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Just to let this car company that people DO re...</td>\n",
       "      <td>2014-03-06 12:38:52</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>let car company people read yelp check review ...</td>\n",
       "      <td>85.49</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6229216</td>\n",
       "      <td>zL4se_Ixdcl8kvTOHCS3rg</td>\n",
       "      <td>s16-BUo-orUsELvMu5ocKg</td>\n",
       "      <td>VH0Ib9S3E-dxbQdQC4rffg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Mistral was the worst dining experience I have...</td>\n",
       "      <td>2010-07-22 18:08:01</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>mistral worst dining experience ever life bad ...</td>\n",
       "      <td>79.19</td>\n",
       "      <td>0.029864</td>\n",
       "      <td>0.502499</td>\n",
       "      <td>0.225888</td>\n",
       "      <td>1777</td>\n",
       "      <td>10</td>\n",
       "      <td>3.82</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id                 user_id  \\\n",
       "0     1073206  JdReKgETiiJEDmshrO4TLw  pyarmAnR-i-qookQamqRTA   \n",
       "1     6229216  zL4se_Ixdcl8kvTOHCS3rg  s16-BUo-orUsELvMu5ocKg   \n",
       "\n",
       "              business_id  stars  useful  funny  cool  \\\n",
       "0  V2GOReqPvr8qpCC7sWfoTw    1.0      17      1     0   \n",
       "1  VH0Ib9S3E-dxbQdQC4rffg    1.0      15      6     4   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Just to let this car company that people DO re...  2014-03-06 12:38:52   \n",
       "1  Mistral was the worst dining experience I have...  2010-07-22 18:08:01   \n",
       "\n",
       "   ...  language                                         text_clean read_ease  \\\n",
       "0  ...        en  let car company people read yelp check review ...     85.49   \n",
       "1  ...        en  mistral worst dining experience ever life bad ...     79.19   \n",
       "\n",
       "   polarity  subjectivity  Adj_ratio  review_count  NumElite  average_stars  \\\n",
       "0 -0.500000      1.000000   0.120000             9         0           3.00   \n",
       "1  0.029864      0.502499   0.225888          1777        10           3.82   \n",
       "\n",
       "   NumofWords  \n",
       "0          56  \n",
       "1         767  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf_train, dtf_test = model_selection.train_test_split(review, test_size=0.3)\n",
    "## get target\n",
    "y_train = dtf_train[\"useful_level\"].values\n",
    "y_test = dtf_test[\"useful_level\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = dtf_train[\"text_clean\"]\n",
    "\n",
    "## create list of lists of unigrams\n",
    "lst_corpus = []\n",
    "for string in corpus1:\n",
    "    lst_words = string.split() \n",
    "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, len(lst_words), 1)]\n",
    "    lst_corpus.append(lst_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = gensim.models.word2vec.Word2Vec(lst_corpus, vector_size=500,  window=8, min_count=1, sg=1)# sg=1 skip gram/sg=0 SBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenize text\n",
    "tokenizer = kprocessing.text.Tokenizer(lower=True, split=' ', \n",
    "                     oov_token=\"NaN\", \n",
    "                     filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(lst_corpus)\n",
    "dic_vocabulary = tokenizer.word_index\n",
    "## create sequence\n",
    "lst_text2seq= tokenizer.texts_to_sequences(lst_corpus)\n",
    "## padding sequence\n",
    "X_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
    "                    maxlen=100, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from:  point received exceptional exceptional service mr kelly security entire team long story short attended concert older person could wait outside cold line wrapped around building block end sight mr kelly understood helped u get venue early allowed u extra time needed get seat without pummeled swarm aggressive people would certainly stampede rush venue mr kelly even one staff member check u midway show pretty rare find venue thats inclusive senior disabled understands need extra time impressed warmth kindness entire team ensuring venue could enjoyed security unsung hero venue thank mr kelly | len: 91\n",
      "to:  [  186   365  1821  1821    12  1498  3942  1139   420   832   114   650\n",
      "   434  2382  3070  1288   196    25    96   243   418   145  1849    65\n",
      "   416  1219   187  2503  1498  3942  2570   770    19     5  1155   487\n",
      "  1022    19   320     2   223     5   423   166 30320 14289  2451    26\n",
      "     9   886 25484  1380  1155  1498  3942    17     3    59   570   136\n",
      "    19  9670   257    73  1244    85  1155   126  8999  3133  5724  6859\n",
      "    69   320     2   659  5147  4681   420   832  8801  1155    25   362\n",
      "  1139 18410  5356  1155   539  1498  3942     0     0     0     0     0\n",
      "     0     0     0     0] | len: 100\n",
      "check:  point  -- idx in vocabulary --> 186\n",
      "vocabulary:  {'NaN': 1, 'time': 2, 'one': 3, 'place': 4, 'get': 5} ... (padding element, 0)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "## list of text: [\"I like this\", ...]\n",
    "len_txt = len(dtf_train[\"text_clean\"].iloc[i].split())\n",
    "print(\"from: \", dtf_train[\"text_clean\"].iloc[i], \"| len:\", len_txt)\n",
    "\n",
    "## sequence of token ids: [[1, 2, 3], ...]\n",
    "len_tokens = len(X_train[i])\n",
    "print(\"to: \", X_train[i], \"| len:\", len(X_train[i]))\n",
    "\n",
    "## vocabulary: \n",
    "print(\"check: \", dtf_train[\"text_clean\"].iloc[i].split()[0], \n",
    "      \" -- idx in vocabulary -->\", \n",
    "      dic_vocabulary[dtf_train[\"text_clean\"].iloc[i].split()[0]])\n",
    "\n",
    "print(\"vocabulary: \", dict(list(dic_vocabulary.items())[0:5]), \"... (padding element, 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = dtf_test[\"text_clean\"]\n",
    "\n",
    "## create list of n-grams\n",
    "lst_corpus2 = []\n",
    "for string in corpus2:\n",
    "    lst_words = string.split()\n",
    "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, \n",
    "                 len(lst_words), 1)]\n",
    "    lst_corpus2.append(lst_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_text2seq2 = tokenizer.texts_to_sequences(lst_corpus2)\n",
    "\n",
    "## padding sequence\n",
    "X_test = kprocessing.sequence.pad_sequences(lst_text2seq2, maxlen=100,\n",
    "             padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start the matrix (length of vocabulary x vector size) with all 0s\n",
    "embeddings = np.zeros((len(dic_vocabulary)+1, 300))\n",
    "for word,idx in dic_vocabulary.items():\n",
    "    ## update the row with vector\n",
    "    try:\n",
    "        embeddings[idx] =  nlp[word]\n",
    "    ## if word not in model then skip and the row stays all 0s\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38630, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16557, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = dtf_test[\"useful_level\"]\n",
    "y_train= dtf_train[\"useful_level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>96</td>\n",
       "      <td>114</td>\n",
       "      <td>145</td>\n",
       "      <td>1064</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>8090</td>\n",
       "      <td>21</td>\n",
       "      <td>865</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>710</td>\n",
       "      <td>11523</td>\n",
       "      <td>11523</td>\n",
       "      <td>12271</td>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>207</td>\n",
       "      <td>42184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4495</td>\n",
       "      <td>3029</td>\n",
       "      <td>578</td>\n",
       "      <td>2370</td>\n",
       "      <td>1379</td>\n",
       "      <td>1175</td>\n",
       "      <td>588</td>\n",
       "      <td>1062</td>\n",
       "      <td>132</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590</td>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "      <td>801</td>\n",
       "      <td>962</td>\n",
       "      <td>2143</td>\n",
       "      <td>371</td>\n",
       "      <td>111</td>\n",
       "      <td>454</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8016</td>\n",
       "      <td>7805</td>\n",
       "      <td>1237</td>\n",
       "      <td>733</td>\n",
       "      <td>3946</td>\n",
       "      <td>41</td>\n",
       "      <td>2697</td>\n",
       "      <td>147</td>\n",
       "      <td>152</td>\n",
       "      <td>12195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>159</td>\n",
       "      <td>1481</td>\n",
       "      <td>7103</td>\n",
       "      <td>269</td>\n",
       "      <td>22445</td>\n",
       "      <td>1283</td>\n",
       "      <td>48430</td>\n",
       "      <td>226</td>\n",
       "      <td>3011</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>260</td>\n",
       "      <td>179</td>\n",
       "      <td>204</td>\n",
       "      <td>11612</td>\n",
       "      <td>8598</td>\n",
       "      <td>265</td>\n",
       "      <td>1247</td>\n",
       "      <td>8598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16552</th>\n",
       "      <td>457</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>559</td>\n",
       "      <td>976</td>\n",
       "      <td>54</td>\n",
       "      <td>14745</td>\n",
       "      <td>2363</td>\n",
       "      <td>495</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16553</th>\n",
       "      <td>159</td>\n",
       "      <td>10860</td>\n",
       "      <td>1403</td>\n",
       "      <td>287</td>\n",
       "      <td>318</td>\n",
       "      <td>51</td>\n",
       "      <td>853</td>\n",
       "      <td>908</td>\n",
       "      <td>43</td>\n",
       "      <td>980</td>\n",
       "      <td>...</td>\n",
       "      <td>576</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>202</td>\n",
       "      <td>859</td>\n",
       "      <td>286</td>\n",
       "      <td>780</td>\n",
       "      <td>6</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16554</th>\n",
       "      <td>604</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>1727</td>\n",
       "      <td>1413</td>\n",
       "      <td>124</td>\n",
       "      <td>726</td>\n",
       "      <td>11335</td>\n",
       "      <td>464</td>\n",
       "      <td>340</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16555</th>\n",
       "      <td>3721</td>\n",
       "      <td>54</td>\n",
       "      <td>1425</td>\n",
       "      <td>105</td>\n",
       "      <td>61</td>\n",
       "      <td>85</td>\n",
       "      <td>3761</td>\n",
       "      <td>4018</td>\n",
       "      <td>333</td>\n",
       "      <td>495</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>334</td>\n",
       "      <td>5533</td>\n",
       "      <td>426</td>\n",
       "      <td>1112</td>\n",
       "      <td>52</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16556</th>\n",
       "      <td>39162</td>\n",
       "      <td>39162</td>\n",
       "      <td>47</td>\n",
       "      <td>1432</td>\n",
       "      <td>6470</td>\n",
       "      <td>47</td>\n",
       "      <td>6470</td>\n",
       "      <td>9827</td>\n",
       "      <td>963</td>\n",
       "      <td>21891</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>1199</td>\n",
       "      <td>9223</td>\n",
       "      <td>933</td>\n",
       "      <td>71</td>\n",
       "      <td>1026</td>\n",
       "      <td>735</td>\n",
       "      <td>982</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16557 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1     2      3      4      5     6      7     8      9   ...  \\\n",
       "0        114     96   114    145   1064     16    13   8090    21    865  ...   \n",
       "1         28      2   710  11523  11523  12271     8    125   207  42184  ...   \n",
       "2       4495   3029   578   2370   1379   1175   588   1062   132    107  ...   \n",
       "3        590    173     5    801    962   2143   371    111   454      6  ...   \n",
       "4        200    159  1481   7103    269  22445  1283  48430   226   3011  ...   \n",
       "...      ...    ...   ...    ...    ...    ...   ...    ...   ...    ...  ...   \n",
       "16552    457     64    12     95    559    976    54  14745  2363    495  ...   \n",
       "16553    159  10860  1403    287    318     51   853    908    43    980  ...   \n",
       "16554    604     64    12   1727   1413    124   726  11335   464    340  ...   \n",
       "16555   3721     54  1425    105     61     85  3761   4018   333    495  ...   \n",
       "16556  39162  39162    47   1432   6470     47  6470   9827   963  21891  ...   \n",
       "\n",
       "         90    91    92    93    94     95    96   97    98     99  \n",
       "0         0     0     0     0     0      0     0    0     0      0  \n",
       "1         0     0     0     0     0      0     0    0     0      0  \n",
       "2         0     0     0     0     0      0     0    0     0      0  \n",
       "3      8016  7805  1237   733  3946     41  2697  147   152  12195  \n",
       "4        45    20   260   179   204  11612  8598  265  1247   8598  \n",
       "...     ...   ...   ...   ...   ...    ...   ...  ...   ...    ...  \n",
       "16552     0     0     0     0     0      0     0    0     0      0  \n",
       "16553   576    74     9    38   202    859   286  780     6   2968  \n",
       "16554     0     0     0     0     0      0     0    0     0      0  \n",
       "16555   237   334  5533   426  1112     52   108    0     0      0  \n",
       "16556   139     8  1199  9223   933     71  1026  735   982    630  \n",
       "\n",
       "[16557 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmbeddingTrain = pd.DataFrame(X_train) #Train set of word2vec features only\n",
    "EmbeddingTest = pd.DataFrame(X_test)   #Test set of word2vec features only\n",
    "EmbeddingTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllotherTrain = dtf_train[[\"useful_level\", \"read_ease\", \"polarity\", \"subjectivity\", \"Adj_ratio\", 'review_count', 'NumElite', 'NumofWords']]\n",
    "AllotherTest = dtf_test[[\"useful_level\", \"read_ease\", \"polarity\", \"subjectivity\", \"Adj_ratio\", 'review_count', 'NumElite', 'NumofWords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt1 = AllotherTrain.loc[:, AllotherTrain.columns != 'useful_level']     #Train set of all other features\n",
    "yt1 = AllotherTrain.loc[:, AllotherTrain.columns == 'useful_level'].values  #Train y\n",
    "Xv1 = AllotherTest.loc[:, AllotherTest.columns != 'useful_level']       #Test set of all other features\n",
    "yv1 = AllotherTest.loc[:, AllotherTest.columns == 'useful_level'].values    #Test y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_ease</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Adj_ratio</th>\n",
       "      <th>review_count</th>\n",
       "      <th>NumElite</th>\n",
       "      <th>NumofWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37710</th>\n",
       "      <td>96.69</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43155</th>\n",
       "      <td>67.28</td>\n",
       "      <td>0.174405</td>\n",
       "      <td>0.572487</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>1039</td>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51175</th>\n",
       "      <td>70.13</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35392</th>\n",
       "      <td>-62.51</td>\n",
       "      <td>0.308604</td>\n",
       "      <td>0.482468</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>1154</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26191</th>\n",
       "      <td>44.42</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16642</th>\n",
       "      <td>90.77</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45173</th>\n",
       "      <td>67.28</td>\n",
       "      <td>0.167246</td>\n",
       "      <td>0.543137</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>1562</td>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28171</th>\n",
       "      <td>-60.48</td>\n",
       "      <td>0.205357</td>\n",
       "      <td>0.577489</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>499</td>\n",
       "      <td>7</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>77.67</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.474661</td>\n",
       "      <td>0.261538</td>\n",
       "      <td>2512</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15135</th>\n",
       "      <td>71.85</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>2512</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38630 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       read_ease  polarity  subjectivity  Adj_ratio  review_count  NumElite  \\\n",
       "37710      96.69  0.600000      0.900000   0.000000            14         0   \n",
       "43155      67.28  0.174405      0.572487   0.241758          1039         4   \n",
       "51175      70.13  0.058333      0.263889   0.203390             1         0   \n",
       "35392     -62.51  0.308604      0.482468   0.210526          1154         1   \n",
       "26191      44.42  0.500000      0.600000   0.125000           115         0   \n",
       "...          ...       ...           ...        ...           ...       ...   \n",
       "16642      90.77  0.520833      0.711111   0.238095           303         0   \n",
       "45173      67.28  0.167246      0.543137   0.183908          1562         4   \n",
       "28171     -60.48  0.205357      0.577489   0.235955           499         7   \n",
       "5848       77.67  0.190000      0.474661   0.261538          2512         7   \n",
       "15135      71.85  0.047619      0.278571   0.191489          2512         7   \n",
       "\n",
       "       NumofWords  \n",
       "37710          17  \n",
       "43155         166  \n",
       "51175         109  \n",
       "35392         157  \n",
       "26191          60  \n",
       "...           ...  \n",
       "16642          36  \n",
       "45173         166  \n",
       "28171         155  \n",
       "5848          133  \n",
       "15135          99  \n",
       "\n",
       "[38630 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec-only evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510599746330857\n"
     ]
    }
   ],
   "source": [
    "model1 = BernoulliNB()\n",
    "model1 = model1.fit(X_train, y_train)\n",
    "y_predict1 = model1.predict(X_test)\n",
    "print(accuracy_score(y_predict1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "#model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           #(\"classifier\", classifier)])\n",
    "## train classifier\n",
    "model1.fit(X_train, y_train.astype(int))\n",
    "## test\n",
    "#X_test = dtf_test[\"text_clean\"].values\n",
    "predicted = model1.predict(X_test)\n",
    "#predicted = np.argmax(predicted,axis=1)\n",
    "predicted_prob = model1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n",
      "Auc: 0.71\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72      7234\n",
      "           1       0.32      0.06      0.10      5231\n",
      "           2       0.35      0.67      0.46      4092\n",
      "\n",
      "    accuracy                           0.51     16557\n",
      "   macro avg       0.45      0.49      0.43     16557\n",
      "weighted avg       0.49      0.51      0.46     16557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, \n",
    "                            multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42605600264947213 0.4543702220461592 0.491379336806338\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score( y_test, y_predict1, average='macro' )\n",
    "p = precision_score(y_test, y_predict1, average='macro')\n",
    "r = recall_score(y_test, y_predict1, average='macro')\n",
    "\n",
    "print(f1, p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5624207283928248\n"
     ]
    }
   ],
   "source": [
    "model2 =  RandomForestClassifier(random_state=4)\n",
    "model2 = model2.fit(X_train, y_train) \n",
    "y_predict2 = model2.predict(X_test)\n",
    "print(accuracy_score(y_predict2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5681584828169355\n"
     ]
    }
   ],
   "source": [
    "model3 =  GradientBoostingClassifier(n_estimators= 50, learning_rate = 0.1,random_state=4)\n",
    "model3 = model3.fit(X_train, y_train)\n",
    "y_predict3 = model3.predict(X_test)\n",
    "print(accuracy_score(y_predict3, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45817479011898293\n"
     ]
    }
   ],
   "source": [
    "model4 = tree.DecisionTreeClassifier(random_state=4)\n",
    "model4 = model4.fit(X_train, y_train) \n",
    "y_predict4 = model4.predict(X_test)\n",
    "print(accuracy_score(y_predict4, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30440297155281754\n"
     ]
    }
   ],
   "source": [
    "model5 =  SGDClassifier(loss=\"squared_loss\")\n",
    "model5 = model5.fit(X_train, y_train)\n",
    "y_predict5 = model5.predict(X_test)\n",
    "print(accuracy_score(y_predict5, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emsemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other features + Word2Vec single classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>useful_level</th>\n",
       "      <th>read_ease</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Adj_ratio</th>\n",
       "      <th>review_count</th>\n",
       "      <th>NumElite</th>\n",
       "      <th>NumofWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>541</td>\n",
       "      <td>730</td>\n",
       "      <td>1877</td>\n",
       "      <td>125</td>\n",
       "      <td>5254</td>\n",
       "      <td>3165</td>\n",
       "      <td>1559</td>\n",
       "      <td>552</td>\n",
       "      <td>129</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.69</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>365</td>\n",
       "      <td>1821</td>\n",
       "      <td>1821</td>\n",
       "      <td>12</td>\n",
       "      <td>1498</td>\n",
       "      <td>3942</td>\n",
       "      <td>1139</td>\n",
       "      <td>420</td>\n",
       "      <td>832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67.28</td>\n",
       "      <td>0.174405</td>\n",
       "      <td>0.572487</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>1039</td>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402</td>\n",
       "      <td>202</td>\n",
       "      <td>610</td>\n",
       "      <td>68</td>\n",
       "      <td>1360</td>\n",
       "      <td>586</td>\n",
       "      <td>3877</td>\n",
       "      <td>127</td>\n",
       "      <td>247</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.13</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2     3     4     5     6     7    8    9  ...  98  99  \\\n",
       "0  541  730  1877   125  5254  3165  1559   552  129  118  ...   0   0   \n",
       "1  186  365  1821  1821    12  1498  3942  1139  420  832  ...   0   0   \n",
       "2  402  202   610    68  1360   586  3877   127  247  126  ...   0   0   \n",
       "\n",
       "   useful_level  read_ease  polarity  subjectivity  Adj_ratio  review_count  \\\n",
       "0             0      96.69  0.600000      0.900000   0.000000            14   \n",
       "1             1      67.28  0.174405      0.572487   0.241758          1039   \n",
       "2             0      70.13  0.058333      0.263889   0.203390             1   \n",
       "\n",
       "   NumElite  NumofWords  \n",
       "0         0          17  \n",
       "1         4         166  \n",
       "2         0         109  \n",
       "\n",
       "[3 rows x 108 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in [\"useful_level\", \"read_ease\", \"polarity\", \"subjectivity\", \"Adj_ratio\", 'review_count', 'NumElite', 'NumofWords']:\n",
    "    EmbeddingTrain[i] = AllotherTrain[i].values\n",
    "EmbeddingTrain.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewXTrain = EmbeddingTrain.loc[:, EmbeddingTrain.columns != 'useful_level']\n",
    "NewYTrain = EmbeddingTrain.loc[:, EmbeddingTrain.columns == 'useful_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"useful_level\", \"read_ease\", \"polarity\", \"subjectivity\", \"Adj_ratio\", 'review_count', 'NumElite', 'NumofWords']:\n",
    "    EmbeddingTest[i] = AllotherTest[i].values\n",
    "NewXTest = EmbeddingTest.loc[:, EmbeddingTest.columns != 'useful_level']\n",
    "NewYTest = EmbeddingTest.loc[:, EmbeddingTest.columns == 'useful_level'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11638\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.60\n",
      "Accuracy of Logistic regression classifier on test set: 0.60\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=5000)\n",
    "logreg.fit(NewXTrain, NewYTrain)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(NewXTrain, NewYTrain)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(NewXTest, NewYTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
